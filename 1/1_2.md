# Sigmoid neurons

Learning algorithms sound terrific. But how can we devise such algorithms for a neural network? Suppose we have a network of perceptrons that we'd like to use to
learn to solve some problem. For example, the inputs to the network might be the raw pixel data from a scanned, handwritten image of a digit. And we'd like the
network to learn weights and biases so that the output from the network correctly classifies the digit. To see how learning might work, suppose we make a small
change in some weight (or bias) in the network. What we'd like is for this small change in weight to cause only a small corresponding change in the output from the
network. As we'll see in a moment, this property will make learning possible. Schematically, here's what we want (obviously this network is too simple to do
handwriting recognition!):

<p align="center">
  <img src="http://neuralnetworksanddeeplearning.com/images/tikz8.png" width="350"/><br></i>
</p>

If it were true that a small change in a weight (or bias) causes only a small change in output, then we could use this fact to modify the weights and biases to get
our network to behave more in the manner we want. For example, suppose the network was mistakenly classifying an image as an "8" when it should be a "9". We could
figure out how to make a small change in the weights and biases so the network gets a little closer to classifying the image as a "9". And then we'd repeat this,
changing the weights and biases over and over to produce better and better output. The network would be learning.

The problem is that this isn't what happens when our network contains perceptrons. In fact, a small change in the weights or bias of any single perceptron in the
network can sometimes cause the output of that perceptron to completely flip, say from 0 to 1. That flip may then cause the behaviour of the rest of the network to
completely change in some very complicated way. So while your "9" might now be classified correctly, the behaviour of the network on all the other images is likely
to have completely changed in some hard-to-control way. That makes it difficult to see how to gradually modify the weights and biases so that the network gets
closer to the desired behaviour. Perhaps there's some clever way of getting around this problem. But it's not immediately obvious how we can get a network of
perceptrons to learn.

We can overcome this problem by introducing a new type of artificial neuron called a *sigmoid neuron*. Sigmoid neurons are similar to perceptrons, but modified so
that small changes in their weights and bias cause only a small change in their output. That's the crucial fact which will allow a network of sigmoid neurons to
learn.

Okay, let me describe the sigmoid neuron. We'll depict sigmoid neurons in the same way we depicted perceptrons:

<p align="center">
  <img src="http://neuralnetworksanddeeplearning.com/images/tikz9.png" width="350"/><br></i>
</p>

Just like a perceptron, the sigmoid neuron has inputs, x1,x2,…. But instead of being just 0 or 1, these inputs can also take on any values between 0 and 1. So, for
instance, 0.638… is a valid input for a sigmoid neuron. Also just like a perceptron, the sigmoid neuron has weights for each input, w1,w2,…, and an overall bias, b.
But the output is not 0 or 1. Instead, it's σ(w⋅x+b), where σ is called the sigmoid function, and is defined by:
