# Implementando nossa rede para classificar dígitos
Alright, let's write a program that learns how to recognize handwritten digits, using stochastic gradient descent and the MNIST training data. We'll do this with a short Python (2.7) program, just 74 lines of code! The first thing we need is to get the MNIST data. If you're a git user then you can obtain the data by cloning the code repository for this book,

    git clone https://github.com/mnielsen/neural-networks-and-deep-learning.git
If you don't use git then you can download the data and code here.

Incidentally, when I described the MNIST data earlier, I said it was split into 60,000 training images, and 10,000 test images. That's the official MNIST 
description. Actually, we're going to split the data a little differently. We'll leave the test images as is, but split the 60,000-image MNIST training set into 
two parts: a set of 50,000 images, which we'll use to train our neural network, and a separate 10,000 image validation set. We won't use the validation data in 
this chapter, but later in the book we'll find it useful in figuring out how to set certain hyper-parameters of the neural network - things like the learning 
rate, and so on, which aren't directly selected by our learning algorithm. Although the validation data isn't part of the original MNIST specification, many 
people use MNIST in this fashion, and the use of validation data is common in neural networks. When I refer to the "MNIST training data" from now on, I'll be 
referring to our 50,000 image data set, not the original 60,000 image data set**As noted earlier, the MNIST data set is based on two data sets collected by NIST, 
the United States' National Institute of Standards and Technology. To construct MNIST the NIST data sets were stripped down and put into a more convenient format 
by Yann LeCun, Corinna Cortes, and Christopher J. C. Burges. See this link for more details. The data set in my repository is in a form that makes it easy to load 
and manipulate the MNIST data in Python. I obtained this particular form of the data from the LISA machine learning laboratory at the University of Montreal [(link)](http://www.deeplearning.net/tutorial/gettingstarted.html).

Apart from the MNIST data we also need a Python library called [Numpy](https://numpy.org/), for doing fast linear algebra. If you don't already have Numpy 
installed, you can get it [here](https://scipy.org/install/).

Let me explain the core features of the neural networks code, before giving a full listing, below. The centerpiece is a Network class, which we use to represent a neural network. Here's the code we use to initialize a Network object:

    class Network(object):

       def __init__(self, sizes):
           self.num_layers = len(sizes)
           self.sizes = sizes
           self.biases = [np.random.randn(y, 1) for y in sizes[1:]]
           self.weights = [np.random.randn(y, x) 
                           for x, y in zip(sizes[:-1], sizes[1:])]
In this code, the list sizes contains the number of neurons in the respective layers. So, for example, if we want to create a Network object with 2 neurons in the 
first layer, 3 neurons in the second layer, and 1 neuron in the final layer, we'd do this with the code:

    net = Network([2, 3, 1])

The biases and weights in the Network object are all initialized randomly, using the Numpy np.random.randn function to generate Gaussian distributions with mean 0 
and standard deviation 1. This random initialization gives our stochastic gradient descent algorithm a place to start from. In later chapters we'll find better 
ways of initializing the weights and biases, but this will do for now. Note that the Network initialization code assumes that the first layer of neurons is an 
input layer, and omits to set any biases for those neurons, since biases are only ever used in computing the outputs from later layers.

Note also that the biases and weights are stored as lists of Numpy matrices. So, for example net.weights[1] is a Numpy matrix storing the weights connecting the 
second and third layers of neurons. (It's not the first and second layers, since Python's list indexing starts at 0.) Since net.weights[1] is rather verbose, 
let's just denote that matrix w. It's a matrix such that w<sup>jk</sup> is the weight for the connection between the k<sup>th</sup> neuron in the second layer, 
and the jth neuron in the third layer. This ordering of the j and k indices may seem strange - surely it'd make more sense to swap the j and k indices around? The 
big advantage of using this ordering is that it means that the vector of activations of the third layer of neurons is:

<p align="center">
  <img src="http://latex2png.com/pngs/5b839f8a17530344ede5d37b9871c84d.png" width="400"/>
   <b><a name="22">(22)</a></b>
</p>

There's quite a bit going on in this equation, so let's unpack it piece by piece. a is the vector of activations of the second layer of neurons. To obtain a′ we 
multiply a by the weight matrix w, and add the vector b of biases. We then apply the function σ elementwise to every entry in the vector wa+b. (This is called 
vectorizing the function σ.) It's easy to verify that [Equation (22)](#22) gives the same result as our earlier rule, [Equation (4)](#4), for computing the output 
of a sigmoid neuron.

## Exercise
> Write out [Equation (22)](#22) in component form, and verify that it gives the same result as the rule [(4)](#4) for computing the output of a sigmoid neuron.
With all this in mind, it's easy to write code computing the output from a Network instance. We begin by defining the sigmoid function:

    def sigmoid(z):
        return 1.0/(1.0+np.exp(-z))
Note that when the input z is a vector or Numpy array, Numpy automatically applies the function sigmoid elementwise, that is, in vectorized form.
We then add a feedforward method to the Network class, which, given an input a for the network, returns the corresponding output**It is assumed that the input a 
is an (n, 1) Numpy ndarray, not a (n,) vector. Here, n is the number of inputs to the network. If you try to use an (n,) vector as input you'll get strange 
results. Although using an (n,) vector appears the more natural choice, using an (n, 1) ndarray makes it particularly easy to modify the code to feedforward 
multiple inputs at once, and that is sometimes convenient.. 

All the method does is applies [Equation (22)](#22) for each layer:

    def feedforward(self, a):
        """Return the output of the network if "a" is input."""
        for b, w in zip(self.biases, self.weights):
            a = sigmoid(np.dot(w, a)+b)
        return a
Of course, the main thing we want our Network objects to do is to learn. To that end we'll give them an SGD method which implements stochastic gradient descent. 
Here's the code. It's a little mysterious in a few places, but I'll break it down below, after the listing.

    def SGD(self, training_data, epochs, mini_batch_size, eta,
            test_data=None):
        """Train the neural network using mini-batch stochastic
        gradient descent.  The "training_data" is a list of tuples
        "(x, y)" representing the training inputs and the desired
        outputs.  The other non-optional parameters are
        self-explanatory.  If "test_data" is provided then the
        network will be evaluated against the test data after each
        epoch, and partial progress printed out.  This is useful for
        tracking progress, but slows things down substantially."""
        if test_data: n_test = len(test_data)
        n = len(training_data)
        for j in xrange(epochs):
            random.shuffle(training_data)
            mini_batches = [
                training_data[k:k+mini_batch_size]
                for k in xrange(0, n, mini_batch_size)]
            for mini_batch in mini_batches:
                self.update_mini_batch(mini_batch, eta)
            if test_data:
                print "Epoch {0}: {1} / {2}".format(
                    j, self.evaluate(test_data), n_test)
            else:
                print "Epoch {0} complete".format(j)
The training_data is a list of tuples (x, y) representing the training inputs and corresponding desired outputs. The variables epochs and mini_batch_size are what 
you'd expect - the number of epochs to train for, and the size of the mini-batches to use when sampling. eta is the learning rate, η. If the optional argument 
test_data is supplied, then the program will evaluate the network after each epoch of training, and print out partial progress. This is useful for tracking 
progress, but slows things down substantially.

The code works as follows. In each epoch, it starts by randomly shuffling the training data, and then partitions it into mini-batches of the appropriate size. This is an easy way of sampling randomly from the training data. Then for each mini_batch we apply a single step of gradient descent. This is done by the code self.update_mini_batch(mini_batch, eta), which updates the network weights and biases according to a single iteration of gradient descent, using just the training data in mini_batch. Here's the code for the update_mini_batch method:

    def update_mini_batch(self, mini_batch, eta):
        """Update the network's weights and biases by applying
        gradient descent using backpropagation to a single mini batch.
        The "mini_batch" is a list of tuples "(x, y)", and "eta"
        is the learning rate."""
        nabla_b = [np.zeros(b.shape) for b in self.biases]
        nabla_w = [np.zeros(w.shape) for w in self.weights]
        for x, y in mini_batch:
            delta_nabla_b, delta_nabla_w = self.backprop(x, y)
            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]
            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]
        self.weights = [w-(eta/len(mini_batch))*nw 
                        for w, nw in zip(self.weights, nabla_w)]
        self.biases = [b-(eta/len(mini_batch))*nb 
                       for b, nb in zip(self.biases, nabla_b)]
Most of the work is done by the line

           delta_nabla_b, delta_nabla_w = self.backprop(x, y)
          
This invokes something called the backpropagation algorithm, which is a fast way of computing the gradient of the cost function. So update_mini_batch works simply by computing these gradients for every training example in the mini_batch, and then updating self.weights and self.biases appropriately.
I'm not going to show the code for self.backprop right now. We'll study how backpropagation works in the next chapter, including the code for self.backprop. For now, just assume that it behaves as claimed, returning the appropriate gradient for the cost associated to the training example x.

Let's look at the full program, including the documentation strings, which I omitted above. Apart from self.backprop the program is self-explanatory - all the 
heavy lifting is done in self.SGD and self.update_mini_batch, which we've already discussed. The self.backprop method makes use of a few extra functions to help 
in computing the gradient, namely sigmoid_prime, which computes the derivative of the σ function, and self.cost_derivative, which I won't describe here. You can 
get the gist of these (and perhaps the details) just by looking at the code and documentation strings. We'll look at them in detail in the next chapter. Note that 
while the program appears lengthy, much of the code is documentation strings intended to make the code easy to understand. In fact, the program contains just 74 
lines of non-whitespace, non-comment code. All the code may be found on GitHub here.

    """
    network.py     


    A module to implement the stochastic gradient descent learning
    algorithm for a feedforward neural network.  Gradients are calculated
    using backpropagation.  Note that I have focused on making the code
    simple, easily readable, and easily modifiable.  It is not optimized,
    and omits many desirable features.
    """

    **** Libraries
    * Standard library
    import random

    * Third-party libraries
    import numpy as np

    class Network(object):

        def __init__(self, sizes):
            """The list ``sizes`` contains the number of neurons in the
            respective layers of the network.  For example, if the list
            was [2, 3, 1] then it would be a three-layer network, with the
            first layer containing 2 neurons, the second layer 3 neurons,
            and the third layer 1 neuron.  The biases and weights for the
            network are initialized randomly, using a Gaussian
            distribution with mean 0, and variance 1.  Note that the first
            layer is assumed to be an input layer, and by convention we
            won't set any biases for those neurons, since biases are only
            ever used in computing the outputs from later layers."""
            self.num_layers = len(sizes)
            self.sizes = sizes
            self.biases = [np.random.randn(y, 1) for y in sizes[1:]]
            self.weights = [np.random.randn(y, x)
                            for x, y in zip(sizes[:-1], sizes[1:])]

        def feedforward(self, a):
            """Return the output of the network if ``a`` is input."""
            for b, w in zip(self.biases, self.weights):
                a = sigmoid(np.dot(w, a)+b)
            return a

        def SGD(self, training_data, epochs, mini_batch_size, eta,
                test_data=None):
            """Train the neural network using mini-batch stochastic
            gradient descent.  The ``training_data`` is a list of tuples
            ``(x, y)`` representing the training inputs and the desired
            outputs.  The other non-optional parameters are
            self-explanatory.  If ``test_data`` is provided then the
            network will be evaluated against the test data after each
            epoch, and partial progress printed out.  This is useful for
            tracking progress, but slows things down substantially."""
            if test_data: n_test = len(test_data)
            n = len(training_data)
            for j in xrange(epochs):
                random.shuffle(training_data)
                mini_batches = [
                    training_data[k:k+mini_batch_size]
                    for k in xrange(0, n, mini_batch_size)]
                for mini_batch in mini_batches:
                    self.update_mini_batch(mini_batch, eta)
                if test_data:
                    print "Epoch {0}: {1} / {2}".format(
                        j, self.evaluate(test_data), n_test)
                else:
                    print "Epoch {0} complete".format(j)

        def update_mini_batch(self, mini_batch, eta):
            """Update the network's weights and biases by applying
            gradient descent using backpropagation to a single mini batch.
            The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``
            is the learning rate."""
            nabla_b = [np.zeros(b.shape) for b in self.biases]
            nabla_w = [np.zeros(w.shape) for w in self.weights]
            for x, y in mini_batch:
                delta_nabla_b, delta_nabla_w = self.backprop(x, y)
                nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]
                nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]
            self.weights = [w-(eta/len(mini_batch))*nw
                           for w, nw in zip(self.weights, nabla_w)]
            self.biases = [b-(eta/len(mini_batch))*nb
                           for b, nb in zip(self.biases, nabla_b)]

        def backprop(self, x, y):
            """Return a tuple ``(nabla_b, nabla_w)`` representing the
            gradient for the cost function C_x.  ``nabla_b`` and
            ``nabla_w`` are layer-by-layer lists of numpy arrays, similar
            to ``self.biases`` and ``self.weights``."""
            nabla_b = [np.zeros(b.shape) for b in self.biases]
            nabla_w = [np.zeros(w.shape) for w in self.weights]
            # feedforward
            activation = x
            activations = [x] # list to store all the activations, layer by layer
            zs = [] # list to store all the z vectors, layer by layer
            for b, w in zip(self.biases, self.weights):
                z = np.dot(w, activation)+b
                zs.append(z)
                activation = sigmoid(z)
                activations.append(activation)
            # backward pass
            delta = self.cost_derivative(activations[-1], y) * \
                sigmoid_prime(zs[-1])
            nabla_b[-1] = delta
            nabla_w[-1] = np.dot(delta, activations[-2].transpose())
            # Note that the variable l in the loop below is used a little
            # differently to the notation in Chapter 2 of the book.  Here,
            # l = 1 means the last layer of neurons, l = 2 is the
            # second-last layer, and so on.  It's a renumbering of the
            # scheme in the book, used here to take advantage of the fact
            # that Python can use negative indices in lists.
            for l in xrange(2, self.num_layers):
                z = zs[-l]
                sp = sigmoid_prime(z)
                delta = np.dot(self.weights[-l+1].transpose(), delta) * sp
                nabla_b[-l] = delta
                nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())
            return (nabla_b, nabla_w)

        def evaluate(self, test_data):
            """Return the number of test inputs for which the neural
            network outputs the correct result. Note that the neural
            network's output is assumed to be the index of whichever
            neuron in the final layer has the highest activation."""
            test_results = [(np.argmax(self.feedforward(x)), y)
                            for (x, y) in test_data]
            return sum(int(x == y) for (x, y) in test_results)

        def cost_derivative(self, output_activations, y):
            """Return the vector of partial derivatives \partial C_x /
            \partial a for the output activations."""
            return (output_activations-y)

    **** Miscellaneous functions
    def sigmoid(z):
        """The sigmoid function."""
        return 1.0/(1.0+np.exp(-z))

    def sigmoid_prime(z):
        """Derivative of the sigmoid function."""
        return sigmoid(z)*(1-sigmoid(z))
How well does the program recognize handwritten digits? Well, let's start by loading in the MNIST data. I'll do this using a little helper program, mnist_loader.py, to be described below. We execute the following commands in a Python shell,

    >>> import mnist_loader
    >>> training_data, validation_data, test_data = \
    ... mnist_loader.load_data_wrapper()
Of course, this could also be done in a separate Python program, but if you're following along it's probably easiest to do in a Python shell.

After loading the MNIST data, we'll set up a Network with 30 hidden neurons. We do this after importing the Python program listed above, which is named network,

    >>> import network
    >>> net = network.Network([784, 30, 10])
Finally, we'll use stochastic gradient descent to learn from the MNIST training_data over 30 epochs, with a mini-batch size of 10, and a learning rate of η=3.0,

    >>> net.SGD(training_data, 30, 10, 3.0, test_data=test_data)
Note that if you're running the code as you read along, it will take some time to execute - for a typical machine (as of 2015) it will likely take a few minutes to run. I suggest you set things running, continue to read, and periodically check the output from the code. If you're in a rush you can speed things up by decreasing the number of epochs, by decreasing the number of hidden neurons, or by using only part of the training data. Note that production code would be much, much faster: these Python scripts are intended to help you understand how neural nets work, not to be high-performance code! And, of course, once we've trained a network it can be run very quickly indeed, on almost any computing platform. For example, once we've learned a good set of weights and biases for a network, it can easily be ported to run in Javascript in a web browser, or as a native app on a mobile device. In any case, here is a partial transcript of the output of one training run of the neural network. The transcript shows the number of test images correctly recognized by the neural network after each epoch of training. As you can see, after just a single epoch this has reached 9,129 out of 10,000, and the number continues to grow,

    Epoch 0: 9129 / 10000
    Epoch 1: 9295 / 10000
    Epoch 2: 9348 / 10000
    ...
    Epoch 27: 9528 / 10000
    Epoch 28: 9542 / 10000
    Epoch 29: 9534 / 10000
That is, the trained network gives us a classification rate of about 95 percent - 95.42 percent at its peak ("Epoch 28")! That's quite encouraging as a first attempt. I should warn you, however, that if you run the code then your results are not necessarily going to be quite the same as mine, since we'll be initializing our network using (different) random weights and biases. To generate results in this chapter I've taken best-of-three runs.

Let's rerun the above experiment, changing the number of hidden neurons to 100. As was the case earlier, if you're running the code as you read along, you should be warned that it takes quite a while to execute (on my machine this experiment takes tens of seconds for each training epoch), so it's wise to continue reading in parallel while the code executes.

    >>> net = network.Network([784, 100, 10])
    >>> net.SGD(training_data, 30, 10, 3.0, test_data=test_data)
Sure enough, this improves the results to 96.59 percent. At least in this case, using more hidden neurons helps us get better results**Reader feedback indicates quite some variation in results for this experiment, and some training runs give results quite a bit worse. Using the techniques introduced in chapter 3 will greatly reduce the variation in performance across different training runs for our networks..

Of course, to obtain these accuracies I had to make specific choices for the number of epochs of training, the mini-batch size, and the learning rate, η. As I mentioned above, these are known as hyper-parameters for our neural network, in order to distinguish them from the parameters (weights and biases) learnt by our learning algorithm. If we choose our hyper-parameters poorly, we can get bad results. Suppose, for example, that we'd chosen the learning rate to be η=0.001,

    >>> net = network.Network([784, 100, 10])
    >>> net.SGD(training_data, 30, 10, 0.001, test_data=test_data)
The results are much less encouraging,

    Epoch 0: 1139 / 10000
    Epoch 1: 1136 / 10000
    Epoch 2: 1135 / 10000
    ...
    Epoch 27: 2101 / 10000
    Epoch 28: 2123 / 10000
    Epoch 29: 2142 / 10000
However, you can see that the performance of the network is getting slowly better over time. That suggests increasing the learning rate, say to η=0.01. If we do that, we get better results, which suggests increasing the learning rate again. (If making a change improves things, try doing more!) If we do that several times over, we'll end up with a learning rate of something like η=1.0 (and perhaps fine tune to 3.0), which is close to our earlier experiments. So even though we initially made a poor choice of hyper-parameters, we at least got enough information to help us improve our choice of hyper-parameters.
In general, debugging a neural network can be challenging. This is especially true when the initial choice of hyper-parameters produces results no better than random noise. Suppose we try the successful 30 hidden neuron network architecture from earlier, but with the learning rate changed to η=100.0:

    >>> net = network.Network([784, 30, 10])
    >>> net.SGD(training_data, 30, 10, 100.0, test_data=test_data)
At this point we've actually gone too far, and the learning rate is too high:

    Epoch 0: 1009 / 10000
    Epoch 1: 1009 / 10000
    Epoch 2: 1009 / 10000
    Epoch 3: 1009 / 10000
    ...
    Epoch 27: 982 / 10000
    Epoch 28: 982 / 10000
    Epoch 29: 982 / 10000
Now imagine that we were coming to this problem for the first time. Of course, we know from our earlier experiments that the right thing to do is to decrease the learning rate. But if we were coming to this problem for the first time then there wouldn't be much in the output to guide us on what to do. We might worry not only about the learning rate, but about every other aspect of our neural network. We might wonder if we've initialized the weights and biases in a way that makes it hard for the network to learn? Or maybe we don't have enough training data to get meaningful learning? Perhaps we haven't run for enough epochs? Or maybe it's impossible for a neural network with this architecture to learn to recognize handwritten digits? Maybe the learning rate is too low? Or, maybe, the learning rate is too high? When you're coming to a problem for the first time, you're not always sure.
The lesson to take away from this is that debugging a neural network is not trivial, and, just as for ordinary programming, there is an art to it. You need to learn that art of debugging in order to get good results from neural networks. More generally, we need to develop heuristics for choosing good hyper-parameters and a good architecture. We'll discuss all these at length through the book, including how I chose the hyper-parameters above.
## Exercício

> Tente criar uma rede neural com apenas duas camadas - uma de entrada e uma de saída, sem camadas escondidas - com 784 e 10 neurônios, respectivamente.
> Treine a rede utilizando gradiente descendente estocástico. Qual o valor da classificação que você consegue alcançar?

Anteriormente, eu pulei os detalhes sobre como os dados MNIST são carregados. É carregado de uma forma direta. Para ilustrar, aqui está o código. 
As estruturas de dados utilizadas para armazenar os dados MNIST são descritas nas strings de documentação - tuplas e listas de objetos `ndarray`
da biblioteca Numpy (pense neles como vetores se você não está familiarizado):

```
"""
mnist_loader
~~~~~~~~~~~~

Uma biblioteca para carregar os dados de imagens do MNIST. Para detalhes acerca das estruturas de dados que são retornadas,
consulte o doc ``load_data`` e ``load_data_wrapper``.  Na prática, ``load_data_wrapper`` é a função usualmente chamada pelo
nosso código.
"""

#### Libraries
# Standard library
import cPickle
import gzip

# Third-party libraries
import numpy as np

def load_data():
    """Retorna os dados MNIST como uma tupla contendo os dados de treinamento, validação e teste.  

    Os dados de treinamento são retornados como uma tupla ``training_data`` de duas entradas. A primeira entrada contém as imagens do treinamento, um ndarray
    numpy com 50000 entradas. Cada entrada é um ndarray com 784 valores, representando 28*28 pixels de uma única imagem do banco MNIST.  
    
    A segunda entrada na tupla ``training_data`` é um ndarray com 50000 entradas. Essas entradas são apenas os valores dos dígitos (0...9) para as imagens correspondentes
    à primeira entrada da tupla;
    
    Os dados ``validation_data`` e ``test_data`` são similares, exceto que cada um contém 10000 imagens.  

    Esse é um formato de dado bom, mas para utilizar em redes neurais, é melhor modificar o formato de ``training_data`` um pouco. Isso é feito na função do tipo
    wrapper ``load_data_wrapper()``, veja abaixo.  
    """
    f = gzip.open('../data/mnist.pkl.gz', 'rb')
    training_data, validation_data, test_data = cPickle.load(f)
    f.close()
    return (training_data, validation_data, test_data)

def load_data_wrapper():
    """Retorna a tupla que contém ``(training_data, validation_data,
    test_data)``. Baseada em ``load_data``, mas o formato é mais conveniente.  
    
    Em particular, ``training_data`` é uma lista contendo 50000 2-tuplas ``(x,y)``, 
    x é um numpy.ndarray de 784 dimensões que contém a imagem de entrada e ``y`` é o numpy.ndarray
    de 10 dimensões que representa o vetor unitário correspondente ao dígito certo de ``x``. `validation_data`` e ``test_data`` são listas contendo
    10000 2-tuplas ``(x, y)``. Em cada caso, ``x`` é um numpy.ndarray de 784 dimensões contendo a imagem de entrada e ``y`` é a correspondente classificação,
    os valores correspondentes a ``x`.  
    
    Obviamente, isso significa que nós estamos utilizando formatos ligeiramente diferentes para
    os dados de treinamento e de validação/teste. Esses formatos acabam sendo os mais convenientes de se utilizar na
    nossa rede neural.  
    tr_d, va_d, te_d = load_data()
    training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]]
    training_results = [vectorized_result(y) for y in tr_d[1]]
    training_data = zip(training_inputs, training_results)
    validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]]
    validation_data = zip(validation_inputs, va_d[1])
    test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]]
    test_data = zip(test_inputs, te_d[1])
    return (training_data, validation_data, test_data)

def vectorized_result(j):
    """Retorna um vetor de 10 dimensões com 1.0 na posição j e zeros no resto. Isso é utilizado para converter um dígito na saída desejada.  
    """
    e = np.zeros((10, 1))
    e[j] = 1.0
    return e
```

Foi dito acima que nosso programa obtém resultados bons. O que isso significa? Bom comparado a o quê? É informativo ter algo simples
(de uma rede não neural) como teste base para comparar e compreender o que significa uma performance boa. A base mais simple de todas, 
claro, é supor um número randômico. Essa estratégia terá sucesso 10% do tempo. Nós estamos fazendo muito melhor que isso!  
Que tal uma base um pouco menos trivial? Vamos tentar uma ideia extremamente simples: iremos ver o quão escura uma imagem é. Por exemplo,
uma imagem de um 2 será tipicamente um pouco mais escura que a imagem de um 1, apenas porque um número maior de pixels é escuro, como
os próximos exemplos ilustram: 

<p align="center">
  <img src="https://user-images.githubusercontent.com/57269172/140234159-63d68da3-6a1b-4735-bd8a-c0b94cf988be.png" width="400"/><br>
  <b><i><a name="2.2"> Figure 1:</a></b> Exemplo dígitos MNIST.</i>
</p>



Isso sugere que utilizando os dados de treinamento para computar a média de pixels escuros para cada dígito 1, 2, 3,...,9. Quando apresentada
uma nova imagem, nós computamos o quão escura a imagem é, e então uma hipótese é formada para qual dígito tem uma média próxima. Esse
procedimento é simples, e fácil de realizar, de forma que não irei escrever explicitamente o código - se você está interessado, está no repositório do
[GitHub](https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/mnist_average_darkness.py). No entanto, é uma grande melhora em comparação à suposições randômicas, obtendo 2,225 de 10,000 imagens testadas equivale a
22,25% de precisão.  

Não é difícil encontrar outras ideias que alcançam uma precisão de 20% a 50%. Se você trabalhar um pouco mais você consegue chegar a 
acima de 50%. Mas para obter uma precisão muito maior, uma estratégia é utilizar algoritmos estabelecidos de machine learning.
Vamos tentar utilizar um dos mais conhecidos, o SVM. Se você não está familiarizado com SVM, não se preocupe, nós não precisaremos 
entender os detalhes de como SVM funciona. Em vez disso, vamos utilizar uma biblioteca de Python chamada [`scikit-learn`](https://scikit-learn.org/stable/), que provém uma 
interface simples em Python para uma biblioteca rápida em C para SVM chamada [`LIBSVM`](http://www.csie.ntu.edu.tw/~cjlin/libsvm/).  

Se nós utilizarmos o classficador SVM de scikit-learn com as configurações padrão, então, será obtido 9,435 de 10,000 imagens corretas.
(O código está disponível [aqui](https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/mnist_svm.py)). Esse é um grande avanço em comparação a nossa abordagem ingênua de classificar uma imagem baseado
em quão escura ela é. De fato, isso significa que o algoritmo SVM tem perfomance quase tão boa quanto nossas redes neurais, apenas um
pouco pior. Nos próximos capítulos nos vamos introduzir novas técnicas que nos permitem melhorar nossas redes neurais de forma que
elas tenham uma performance melhor que SVM. 

Entretanto, esse não é o final da história. O resultado 9,435 de 10,000 é obtido para os parâmetros padrões de SVM. O algoritmo tem um
número de parâmetros ajustáveis, e é possível encontrar parâmetros que melhorem essa performance. Eu não farei essa procura
explicitamente, mas mandarei você para esse [post](https://peekaboo-vision.blogspot.com/2010/09/mnist-for-ever.html) de [Andreas Mueller](https://peekaboo-vision.blogspot.com/) se você se interessar em saber mais. Mueller mostra que com
algum trabalho otimizando os parâmetros é possível chegar a uma performance de 98,5% de precisão. Em outras palavras, um SVM bem
parametrizado apenas faz um error de um dígito em 70. Isso é muito bom! Será que as redes neurais conseguem fazer melhor?

De fato, elas conseguem. Atualmente, redes neurais bem feitas supera, qualquer outra ténica para resolver MNIST, incluindo SVM. O recorde
atual (2013) foi a classificação de 9,979 de 10,000 imagens corretamente. Isso foi feito por Li Wan, [Matthew Zeiler](https://www.matthewzeiler.com/), Sixin Zhang, [Yann
LeCun](http://yann.lecun.com/) e [Rob Fergus](https://cs.nyu.edu/~fergus/pmwiki/pmwiki.php). Nós veremos a maioria das técnicas utilizadas por ele nos próximos capítulos do livro. Naquele nível, a performance
se torna bem próxima da equivalente humana e é discutivelmente melhor, já que algumas das imagens do MNIST são difíceis para até
humanos reconhecerem com confiança, por exemplo: 


<p align="center">
  <img src="https://user-images.githubusercontent.com/57269172/140234241-77a2bf59-efd5-448c-a64d-c67f370af282.png" width="400"/><br>
  <b><i><a name="2.2"> Figure 2:</a></b> Imagens de dígitos do MNIST.</i>
</p>


Eu confio que você concordará que essas imagens são difíceis de classificar! Com imagens como essa nos dados do MNIST é extraordinário que as
redes neurais conseguem classificar com precisão todas menos 21 do teste de 10000 imagens. Tipicamente, quando programamos, nós acreditamos
que resolver um problema complicado como reconhecer dígitos do MNIST requer um algoritmo complicado. Mas até as redes neurais no periódico
Wan et al apenas menciona algoritmos simples, variações dos algoritmos que foram vistos nesse capítulo. Toda a complexidade é compreendida
automaticamente pelos dados de treinamento. De alguma forma, a moral de ambos nossos resultados e nesses artigos sofisticados, é que para
alguns problemas:

```
algoritmo sofisticado <= algoritmo de aprendizagem simples + bons dados de treinamento
```

