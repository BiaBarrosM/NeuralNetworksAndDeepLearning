# The backpropagation algorithm

The backpropagation equations provide us with a way of computing the gradient of the cost function. Let's explicitly write this out in the form of an algorithm:

1) **Input x**: Set the corresponding activation a1 for the input layer.
2) **Feedforward**: For each l = 2, 3, …, L compute z(l) = w(l)a(l−1)+b(l) and a(l)=σ(z(l)).
3) **Output error δ(L)**: Compute the vector δ(L) = ∇C ⊙ σ′(z(L)).
4) **Backpropagate the error**: For each l = L−1, L−2, …, 2 compute δ(l) = ((w(l)+1)Tδ(l)+1) ⊙ σ′(z(l)).
5) **Output**: The gradient of the cost function is given by <img src="https://user-images.githubusercontent.com/48807586/137418288-6465d459-260b-4e97-ae43-1128c006c5f8.png" width="80"/> and <img src="https://user-images.githubusercontent.com/48807586/137418306-a44219d2-315b-4a5e-ac02-ff9547a4333c.png" width="60"/>.

Examining the algorithm you can see why it's called _backpropagation_. We compute the error vectors δ(l) backward, starting from the final layer. It may seem peculiar that we're going through the network backward. But if you think about the proof of backpropagation, the backward movement is a consequence of the fact that the cost is a function of outputs from the network. To understand how the cost varies with earlier weights and biases we need to repeatedly apply the chain rule, working backward through the layers to obtain usable expressions.

## Exercises

- **Backpropagation with a single modified neuron**: Suppose we modify a single neuron in a feedforward network so that the output from the neuron is given by <img src="https://user-images.githubusercontent.com/48807586/137418435-71db6ab8-22d2-40b6-9e48-b259eabc1995.png" width="80"/>, where f is some function other than the sigmoid. How should we modify the backpropagation algorithm in this case?
- **Backpropagation with linear neurons**: Suppose we replace the usual non-linear σ function with σ(z) = z throughout the network. Rewrite the backpropagation algorithm for this case.

As I've described it above, the backpropagation algorithm computes the gradient of the cost function for a single training example, C = C(x). In practice, it's common to combine backpropagation with a learning algorithm such as stochastic gradient descent, in which we compute the gradient for many training examples. In particular, given a mini-batch of m training examples, the following algorithm applies a gradient descent learning step based on that mini-batch:

1) **Input a set of training examples**
2) **For each training example x**: Set the corresponding input activation a(x,1), and perform the following steps:
- **Feedforward**: For each l = 2, 3, …, L compute z(x,l) = w(l)a(x,l−1)+b(l) and a(x,l) = σ(z(x,l)).
- **Output error δ(x,L)**: Compute the vector δ(x,L) = ∇C(x) ⊙ σ′(z(x,L)).
- **Backpropagate the error**: For each l = L−1, L−2, …, 2 compute δ(x,l)=[(w(l+1))δ(x,l+1)] ⊙ σ′(z(x,l)).
3) **Gradient descent**: For each l = L, L−1, …, 2 update the weights according to the rule <img src="https://user-images.githubusercontent.com/48807586/137418606-27d13a4a-dace-4ba2-be8a-d2db4d90baec.png" width="200"/>, and the biases according to the rule <img src="https://user-images.githubusercontent.com/48807586/137418613-882192c6-4890-40fc-af16-7adb31bba6bb.png" width="150"/>.

Of course, to implement stochastic gradient descent in practice you also need an outer loop generating mini-batches of training examples, and an outer loop stepping through multiple epochs of training. I've omitted those for simplicity.
